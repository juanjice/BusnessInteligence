{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sheet 8 - Business Intelligence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from template import *\n",
    "from collections import Counter\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Show the following  \n",
    "a) if X; Y are itemsets and X C= Y , then sup(X) >= sup(Y )  \n",
    "b)if X; Y are itemsets and X C= Y , then t(X) Ↄ= t(Y )  \n",
    "c)if S; T are tidsets and S C= T , then i(S) Ↄ= i(T)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2 (4 Points) In this exercise, we will use the transaction view on itemsets. You\n",
    "can use the given implementations to read in a transaction database and set utilities such as\n",
    "computing the diﬀerence of sets/lists. Note that we treat itemsets as python lists (not numpy\n",
    "arrays). In the following db refers to a list of lists (a list of transactions, which are encoded\n",
    "as lists)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Write functions apriori(db, minsup), eclat(db, minsup), and declat(db, minsup)\n",
    "that run the respective algorithms and return the set of frequent itemsets (with threshold\n",
    "minsup). Run the three algorithms on the shop dataset and report the runtimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apriori(db,minsup):\n",
    "    items=set([x for l in db for x in l])\n",
    "    items=np.sort(np.array(list(items)))\n",
    "    print(items)\n",
    "    k=1\n",
    "    Ck=[]\n",
    "    for i,combo in enumerate(combinations(items,2)):\n",
    "        Ck.append(combo)    \n",
    "    Ck=np.array(Ck)\n",
    "    F=[]\n",
    "    while Ck.size != 0:        \n",
    "        \n",
    "        supportCk=computeSupport(db,Ck)\n",
    "        newCk=[]\n",
    "        Ck=np.delete(Ck,np.where(supportCk<minsup),0)\n",
    "        print(Ck,\"-k:\",k,\"len Ck:\",Ck.shape[0],\"support=\",supportCk)         \n",
    "        for index,i in enumerate(Ck):\n",
    "            brothers=Ck[np.all(Ck[:,np.arange(k)]==Ck[index,0:k],axis=1),:]              \n",
    "            for j in brothers:\n",
    "                if j[k]>i[k]:\n",
    "                    concat=np.concatenate((j[j>i[k]],i),0)                \n",
    "                    newCk.append(np.unique(concat))        \n",
    "        innecesariSons=[]\n",
    "        for i,sons in enumerate(newCk):\n",
    "            \n",
    "            for combo in combinations(sons,k+1):\n",
    "                condition=np.isin(Ck, combo)\n",
    "                condition=np.any(condition[:,0]* condition[:,1])                \n",
    "                if not(condition):\n",
    "                    innecesariSons.append(i)\n",
    "        newCk=np.delete(newCk,innecesariSons,0)\n",
    "        F.append(Ck)\n",
    "        Ck=np.array(newCk)\n",
    "        k+=1\n",
    "    \n",
    "    return F\n",
    "def computeSupport(db,Ck):\n",
    "    arr=pd.DataFrame(db,dtype=int).values\n",
    "    support=np.zeros(Ck.shape[0],dtype=int)\n",
    "    shapex=Ck.shape[1]\n",
    "    for i,tidset in enumerate(Ck):\n",
    "        mask=np.isin(arr,tidset)\n",
    "        result=np.sum(mask,1)        \n",
    "        support[i]=np.count_nonzero(result== shapex)    \n",
    "    return support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[[1 2]\n",
      " [1 4]\n",
      " [1 5]\n",
      " [2 3]\n",
      " [2 4]\n",
      " [2 5]\n",
      " [3 5]\n",
      " [4 5]] -k: 1 len Ck: 8 support= [4 2 3 4 4 4 5 2 3 3]\n",
      "[[1 2 4]\n",
      " [1 2 5]\n",
      " [1 4 5]\n",
      " [2 3 5]\n",
      " [2 4 5]] -k: 2 len Ck: 5 support= [3 4 3 3 3]\n",
      "[[1 2 4 5]] -k: 3 len Ck: 1 support= [3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[1, 2],\n",
       "        [1, 4],\n",
       "        [1, 5],\n",
       "        [2, 3],\n",
       "        [2, 4],\n",
       "        [2, 5],\n",
       "        [3, 5],\n",
       "        [4, 5]]),\n",
       " array([[1, 2, 4],\n",
       "        [1, 2, 5],\n",
       "        [1, 4, 5],\n",
       "        [2, 3, 5],\n",
       "        [2, 4, 5]]),\n",
       " array([[1, 2, 4, 5]])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apriori(readTransactionalDatabase(\"../exampleset.dat\"), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eclat(db,minsup):\n",
    "    F\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "1. missing: 0/4\n",
    "2. The implementation of apriori looks ok, you only missed the itemsets of size 1. eclat, declat and part 2 are missing: 1/4.\n",
    "\n",
    "Total score: 1/8"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
